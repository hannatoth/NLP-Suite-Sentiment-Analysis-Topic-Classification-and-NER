{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: VADER\n",
    "\n",
    "```\n",
    "INPUT SENTENCE 1 I love apples\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}\n",
    "\n",
    "INPUT SENTENCE 2 I don't love apples\n",
    "VADER OUTPUT {'neg': 0.627, 'neu': 0.373, 'pos': 0.0, 'compound': -0.5216}\n",
    "\n",
    "INPUT SENTENCE 3 I love apples :-)\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.133, 'pos': 0.867, 'compound': 0.7579}\n",
    "\n",
    "INPUT SENTENCE 4 These houses are ruins\n",
    "VADER OUTPUT {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}\n",
    "\n",
    "INPUT SENTENCE 5 These houses are certainly not considered ruins\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.51, 'pos': 0.49, 'compound': 0.5867}\n",
    "\n",
    "INPUT SENTENCE 6 He lies in the chair in the garden\n",
    "VADER OUTPUT {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.4215}\n",
    "\n",
    "INPUT SENTENCE 7 This house is like any house\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.3612}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT SENTENCE 1 I love apples\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'compound': 0.6369}\n",
    "Insights: VADER correctly identifies it as positive, as it is a very simple sentence. \n",
    "\n",
    "INPUT SENTENCE 2 I don't love apples\n",
    "VADER OUTPUT {'neg': 0.627, 'neu': 0.373, 'pos': 0.0, 'compound': -0.5216}\n",
    "Insights: VADER correctly identifies it as negative, as it detects the negating don't before the like.\n",
    "\n",
    "INPUT SENTENCE 3 I love apples :-)\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.133, 'pos': 0.867, 'compound': 0.7579}\n",
    "Insights: VADER correctly identifies it as positive, this time with a higher pos score compared to sentence 1, due to the emoticon, which VADER correctly detects: \":-)\"\n",
    "\n",
    "INPUT SENTENCE 4 These houses are ruins\n",
    "VADER OUTPUT {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}\n",
    "Insights: While the neutral score is the highest (even though the neg score is also high), the compound score also indicates that thhe sentence carries negative sentiment.\n",
    "\n",
    "INPUT SENTENCE 5 These houses are certainly not considered ruins\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.51, 'pos': 0.49, 'compound': 0.5867}\n",
    "Insights: VADER correctly identifies the sentence via the normalized compound score. Again, it correctly identified the negating word before the part of the sentence which carries the sentiment.\n",
    "\n",
    "INPUT SENTENCE 6 He lies in the chair in the garden\n",
    "VADER OUTPUT {'neg': 0.286, 'neu': 0.714, 'pos': 0.0, 'compound': -0.4215}\n",
    "Insights: VADER correctly identifies the sentence, based only off of the neg, neu and pos scores, however we can observe that VADERS lexicon might have a problem with the nuances of the word \"lies\", which gets incorrectly interpreted as an overall negative sentiment, as can be seen in the compound score.\n",
    "\n",
    "INPUT SENTENCE 7 This house is like any house\n",
    "VADER OUTPUT {'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.3612}\n",
    "Insights: VADER correctly identifies it as neutral, however the compound score reflects a positive sentiment, probably due to the wor \"like\"\n",
    "\n",
    "We can conclude that VADER gets a high accuracy score, however it must be mentioned that these sentences overall do not carry that many nuances, compared to the everyday language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting 50 tweets for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweets = json.load(open('my_tweets.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'sentiment_label': 'neg', 'text_of_tweet': \"Me, ready to go at supermarket during the #COVID19 outbreak. Not because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\", 'tweet_url': 'https://t.co/usmuaLq72n'}\n"
     ]
    }
   ],
   "source": [
    "for id_, tweet_info in my_tweets.items():\n",
    "    print(id_, tweet_info)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_output_to_label(vader_output):\n",
    "    \"\"\"\n",
    "    map vader output e.g.,\n",
    "    {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
    "    to one of the following values:\n",
    "    a) positive float -> 'positive'\n",
    "    b) 0.0 -> 'neutral'\n",
    "    c) negative float -> 'negative'\n",
    "    \n",
    "    :param dict vader_output: output dict from vader\n",
    "    \n",
    "    :rtype: str\n",
    "    :return: 'negative' | 'neutral' | 'positive'\n",
    "    \"\"\"\n",
    "    compound = vader_output['compound']\n",
    "    \n",
    "    if compound < 0:\n",
    "        return 'negative'\n",
    "    elif compound == 0.0:\n",
    "        return 'neutral'\n",
    "    elif compound > 0.0:\n",
    "        return 'positive'\n",
    "    \n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.0}) == 'neutral'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.01}) == 'positive'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': -0.01}) == 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') # 'en_core_web_sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vader(textual_unit, \n",
    "              lemmatize=False, \n",
    "              parts_of_speech_to_consider=None,\n",
    "              verbose=0):\n",
    "    \"\"\"\n",
    "    Run VADER on a sentence from spacy\n",
    "    \n",
    "    :param str textual unit: a textual unit, e.g., sentence, sentences (one string)\n",
    "    (by looping over doc.sents)\n",
    "    :param bool lemmatize: If True, provide lemmas to VADER instead of words\n",
    "    :param set parts_of_speech_to_consider:\n",
    "    -None or empty set: all parts of speech are provided\n",
    "    -non-empty set: only these parts of speech are considered.\n",
    "    :param int verbose: if set to 1, information is printed\n",
    "    about input and output\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: vader output dict\n",
    "    \"\"\"\n",
    "    doc = nlp(textual_unit)\n",
    "        \n",
    "    input_to_vader = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "\n",
    "            to_add = token.text\n",
    "\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "\n",
    "                if to_add == '-PRON-': \n",
    "                    to_add = token.text\n",
    "\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add) \n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print()\n",
    "        print('INPUT SENTENCE', sent)\n",
    "        print('INPUT TO VADER', input_to_vader)\n",
    "        print('VADER OUTPUT', scores)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOLD LABELS: ['neg', 'neu', 'neu', 'pos', 'neg', 'neg', 'neg', 'neg', 'neg', 'neg', 'pos', 'neg', 'pos', 'neg', 'pos', 'neu', 'neg', 'neu', 'pos', 'neu', 'neg', 'pos', 'neu', 'pos', 'neg', 'neg', 'neg', 'pos', 'neg', 'neg', 'neg', 'neu', 'neg', 'neu', 'neu', 'pos', 'neu', 'neg', 'pos', 'pos', 'neg', 'neg', 'neu', 'neu', 'neg', 'neg', 'pos', 'pos', 'neu', 'neg']\n",
      "VADER LABELS: ['pos', 'neg', 'neg', 'pos', 'neu', 'neu', 'pos', 'neu', 'neu', 'neu', 'pos', 'neu', 'pos', 'neu', 'neu', 'pos', 'neu', 'neu', 'pos', 'pos', 'neu', 'pos', 'neg', 'pos', 'neu', 'neu', 'pos', 'pos', 'neu', 'neu', 'pos', 'neu', 'pos', 'pos', 'neu', 'pos', 'neu', 'neu', 'pos', 'neg', 'neu', 'neu', 'pos', 'pos', 'pos', 'neu', 'pos', 'pos', 'neg', 'neu']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg      0.000     0.000     0.000        24\n",
      "         neu      0.174     0.308     0.222        13\n",
      "         pos      0.500     0.846     0.629        13\n",
      "\n",
      "    accuracy                          0.300        50\n",
      "   macro avg      0.225     0.385     0.284        50\n",
      "weighted avg      0.175     0.300     0.221        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tweets = []\n",
    "all_vader_output = []\n",
    "gold = []\n",
    "\n",
    "# settings (to change for different experiments)\n",
    "to_lemmatize = True \n",
    "pos = set()\n",
    "i = -1\n",
    "for id_, tweet_info in my_tweets.items():\n",
    "    i += 1\n",
    "    the_tweet = tweet_info['text_of_tweet']\n",
    "    vader_output = run_vader(the_tweet) # run vader\n",
    "    vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "    \n",
    "    tweets.append(the_tweet)\n",
    "    all_vader_output.append(vader_label)\n",
    "    gold.append(tweet_info['sentiment_label'])\n",
    "    \n",
    "for i in range(len(all_vader_output)):\n",
    "    if all_vader_output[i] == 'neutral':\n",
    "        all_vader_output[i] = 'neg'\n",
    "    elif all_vader_output[i] == 'positive':\n",
    "        all_vader_output[i] = 'pos'\n",
    "    else:\n",
    "        all_vader_output[i] = 'neu'\n",
    "\n",
    "print(\"GOLD LABELS:\", gold)\n",
    "print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output, digits=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrongly classified NEGATIVE tweet: neg pos 0 Me, ready to go at supermarket during the #COVID19 outbreak. Not because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\n",
      "wrongly classified NEGATIVE tweet: neg neu 4 #COVID19 makes us dumber. Large study shows cognitive impairment (memory, reasoning, executive function) in those who’ve been infected. Mult doses of #vaccine associated w/ LESS cognitive impairment & mult infections w/ MORE cognitive impairment. \n",
      "wrongly classified NEGATIVE tweet: neg neu 5 If you know you’re sick with *something* but it’s “NOT COVID” you should still wear a mask. Nasty!\n",
      "wrongly classified NEGATIVE tweet: neg pos 6 1/2 the world volunteered to shorten their lives so they could protect themselves from a disease that was over 97% survivable. (Same rate as the flu)\n",
      "wrongly classified NEGATIVE tweet: neg neu 7 Does anyone else deal with anger? I know it is normal to feel frustrated, but the emotions I feel seem a little extreme. I can’t help but think covid has something to do with this. If yes, anyone have any ideas to combat it? I deal with a lot of heart issues, so anger is a no-no\n",
      "wrongly classified NEGATIVE tweet: neg neu 8 When your usual grocery shopping @woolworths turns into a toilet paper fight in the supermarket aisle. Yikes. #toiletpaperpanic for the #coronavirus has taken a whole new level.\n",
      "wrongly classified NEGATIVE tweet: neg neu 11 I bought #Spam, for God's sake. Spam. Goddamn grocery store shelves were picked clean. I won't starve, but my diet's going to be shite for the next week or so.\n",
      "wrongly classified NEGATIVE tweet: neg neu 13 @AnnCoulter This is media driven hysteria. Its causing people who work at sporting events, food trucks, etc to lose their jobs. Not to mention the damage to the stock market. Truly despicable. My family has deleted all @FoxNews shows. We are done\n",
      "wrongly classified NEGATIVE tweet: neg neu 45 For anyone whining about #NewYearsEve dinner plans getting “ruined” because you can’t order booze past 8pm, let me remind you nearly 900 lives have been lost in #BC since this pandemic started.\n",
      "wrongly classified NEGATIVE tweet: neg neu 49 Imagine if there were a beach with shark infested waters with a sign that says, “Shark infested waters, over 300,000 people were killed swimming here last year. If you are attacked you’re also putting the lives of lifeguards who swim out to save you at risk.”That’s COVID.\n",
      "wrongly classified NEUTRAL tweet: neu neg 1 COVID-19 restrictions sparking a run on cannabis stores. They're not closed yet! But Customers are stocking up on cannabis this weekend, preparing for what could be more retail store restrictions in coming days.\n",
      "wrongly classified NEUTRAL tweet: neu neg 2 Was at the supermarket today. Didn't buy toilet paper.\n",
      "wrongly classified NEUTRAL tweet: neu pos 15 The grocery store was PACKED at 6am this morning, in west Henrico VA. #VA07 Early Saturday, is when I shop in relative peace. Not THIS morning.\n",
      "wrongly classified NEUTRAL tweet: neu pos 19 A package that arrived at LAX from the United Kingdom was supposedly carrying purified water, but CBP officers found vials of white liquid labeled Corona Virus 2019nconv (COVID-19)\n",
      "wrongly classified NEUTRAL tweet: neu neg 22 ‘#Australia had some of the most stringent border checks you could get and this time last year despite all the testing, the fact few people could go in, the #Omicron variant got in’\n",
      "wrongly classified NEUTRAL tweet: neu pos 33 Neighborhoods in NYC are up to 29.4% for percent positive for #COVID19 over past 7 days! NYC's COVID Positivity rate is now 17%!NYC needs to mandate masks, @NYCMayor @NYCPA @NYCHealthCommr. You can't ignore COVID surge. You need to take action and help protect people's lives.\n",
      "wrongly classified NEUTRAL tweet: neu pos 42 A NSW person with #covid19 attended Smile Buffalo Thai restaurant in Black Rock on December 21 which was the event that led to 3 people testing positive. Before borders closed.\n",
      "wrongly classified NEUTRAL tweet: neu pos 43 Wednesday's #COVID19 update:- 1,316 new cases, totaling 141,186 cases statewide - 33 additional deaths, totaling 2,436 - 792 current COVID-19 hospitalizations Please take every action you can to keep each other safe.\n",
      "wrongly classified NEUTRAL tweet: neu neg 48 10,776 doses of #coronavirus vaccine were administered today in Canada, bring the total to 83,202 to date. (417,000 doses have been received)\n",
      "wrongly classified POSIITIVE tweet: pos neu 14 My local corner shop topped up prices on everything. A typical 20 basket cost 33 today. I argued the price increase. He stated he won't survive against the main supermarkets. I willingly paid the 33 and rounded up to 35. I'd be lost without him.\n",
      "wrongly classified POSIITIVE tweet: pos neg 39 #Israel has vaccinated 30% of all population over 60. At present pace of over 100,000 inoculated daily,  Israel will vaccinate all remaining 60+ citizens in approx 10 days.\n"
     ]
    }
   ],
   "source": [
    "wrongly_classified_positive_indexes = [14, 39]\n",
    "wrongly_classified_negative_indexes = [0, 4, 5, 6, 7, 8, 11, 13, 49, 45]\n",
    "wrongly_classified_neutrals_indexes = [1, 2, 15, 19, 22, 33, 48, 43, 42]\n",
    "\n",
    "#negatives\n",
    "for i in range(len(gold)):\n",
    "    if i in wrongly_classified_negative_indexes:\n",
    "        print(\"wrongly classified NEGATIVE tweet:\", gold[i], all_vader_output[i], i, tweets[i])\n",
    "\n",
    "#neutrals\n",
    "for i in range(len(gold)):\n",
    "    if i in wrongly_classified_neutrals_indexes:\n",
    "        print(\"wrongly classified NEUTRAL tweet:\", gold[i], all_vader_output[i], i, tweets[i])\n",
    "\n",
    "#positives\n",
    "for i in range(len(gold)):\n",
    "    if i in wrongly_classified_positive_indexes:\n",
    "        print(\"wrongly classified POSIITIVE tweet:\", gold[i], all_vader_output[i], i, tweets[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part a, \n",
    "\n",
    "Precision: Precision is pretty low across all categories, with 0 precision for 'neg' and relatively low precision for 'neu' and 'pos'. This means that the model incorrectly classified many instances as belonging to a certain each class and didn't get a single 'neg' correct. At least it got 50% of the positive examples correct.\n",
    "\n",
    "Recall: In this evaluation, recall is low for 'neg' and 'neu' but relatively higher for 'pos'. Low recall suggests that the model failed to capture a significant portion of instances belonging to the 'neg' and 'neu' categories. However each time the system predicted a positive it was actually most likely a positive, this along with the low .5 precision means that the system is very caucious. \n",
    "\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. Here, the F1-score is generally low across all sentiment categories. A low F1-score alos demonstrates the poor performance in both precision and recall\n",
    "\n",
    "Support: Support indicates the number of actual instances belonging to each class. Here, 'neg' has the highest support, followed by 'neu' and 'pos'.\n",
    "\n",
    "Accuracy: Accuracy measures the overall correctness of the classifier across all classes. In this case, the accuracy is low at 30%, indicating that the model's performance is dreadful :(\n",
    "\n",
    "Part b,\n",
    "\n",
    "**Misclassified negatives:**  \n",
    "\n",
    "1, wrongly classified NEGATIVE tweet: neg pos 0 Me, ready to go at supermarket during the #COVID19 outbreak. Not because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\n",
    "\n",
    "2,wrongly classified NEGATIVE tweet: neg neu 4 #COVID19 makes us dumber. Large study shows cognitive impairment (memory, reasoning, executive function) in those who’ve been infected. Mult doses of #vaccine associated w/ LESS cognitive impairment & mult infections w/ MORE cognitive impairment. \n",
    "\n",
    "\n",
    "3,wrongly classified NEGATIVE tweet: neg neu 5 If you know you’re sick with *something* but it’s “NOT COVID” you should still wear a mask. Nasty!\n",
    "\n",
    "\n",
    "\n",
    "**Misclassified neutrals:**\n",
    "\n",
    "1, wrongly classified NEUTRAL tweet: neu neg 1 COVID-19 restrictions sparking a run on cannabis stores. They're not closed yet! But Customers are stocking up on cannabis this weekend, preparing for what could be more retail store restrictions in coming days.\n",
    "\n",
    "\n",
    "2, wrongly classified NEUTRAL tweet: neu pos 15 The grocery store was PACKED at 6am this morning, in west Henrico VA. #VA07 Early Saturday, is when I shop in relative peace. Not THIS morning.\n",
    "\n",
    "\n",
    "3, wrongly classified NEUTRAL tweet: neu neg 22 ‘#Australia had some of the most stringent border checks you could get and this time last year despite all the testing, the fact few people could go in, the #Omicron variant got in’\n",
    " \n",
    "\n",
    "**Misclassified positives:**\n",
    "\n",
    "1,\n",
    "wrongly classified POSIITIVE tweet: pos neu 14 My local corner shop topped up prices on everything. A typical 20 basket cost 33 today. I argued the price increase. He stated he won't survive against the main supermarkets. I willingly paid the 33 and rounded up to 35. I'd be lost without him.\n",
    "\n",
    "2,\n",
    "wrongly classified POSIITIVE tweet: pos neg 39 #Israel has vaccinated 30% of all population over 60. At present pace of over 100,000 inoculated daily,  Israel will vaccinate all remaining 60+ citizens in approx 10 days.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER on the set of airline tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/aronf/Desktop/text-mining/code/ba-text-mining/lab_sessions/lab3/airlinetweets\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "airline_tweets_folder = cwd.joinpath('airlinetweets')\n",
    "print('path:', airline_tweets_folder)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(sentiment):\n",
    "    directory = f'{airline_tweets_folder}/{sentiment}/'\n",
    "    # List to store the text content of all files\n",
    "    text_content = []\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text_content.append(file.read())\n",
    "    return text_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_1(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_1('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_1('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_1('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.29      0.21      0.25      1750\n",
      "         neu       0.17      0.12      0.14      1515\n",
      "         pos       0.56      0.88      0.68      1490\n",
      "\n",
      "    accuracy                           0.39      4755\n",
      "   macro avg       0.34      0.41      0.36      4755\n",
      "weighted avg       0.34      0.39      0.35      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"BASE\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_2(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet, lemmatize=True) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEMMA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.30      0.21      0.24      1750\n",
      "         neu       0.17      0.13      0.15      1515\n",
      "         pos       0.56      0.88      0.68      1490\n",
      "\n",
      "    accuracy                           0.40      4755\n",
      "   macro avg       0.34      0.41      0.36      4755\n",
      "weighted avg       0.34      0.40      0.35      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_2('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_2('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_2('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output\n",
    "print(\"LEMMA\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_3(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet, parts_of_speech_to_consider={'ADJ'}) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.35      0.68      0.46      1750\n",
      "         neu       0.08      0.02      0.04      1515\n",
      "         pos       0.66      0.44      0.53      1490\n",
      "\n",
      "    accuracy                           0.39      4755\n",
      "   macro avg       0.37      0.38      0.34      4755\n",
      "weighted avg       0.36      0.39      0.35      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_3('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_3('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_3('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output\n",
    "print(\"ADJ\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_4(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet, lemmatize=True, parts_of_speech_to_consider={'ADJ'}) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEMMA+ADJ\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.35      0.67      0.46      1750\n",
      "         neu       0.08      0.02      0.04      1515\n",
      "         pos       0.66      0.44      0.53      1490\n",
      "\n",
      "    accuracy                           0.39      4755\n",
      "   macro avg       0.37      0.38      0.34      4755\n",
      "weighted avg       0.36      0.39      0.35      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_4('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_4('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_4('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output\n",
    "print(\"LEMMA+ADJ\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_5(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet, parts_of_speech_to_consider={'NOUN'}) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUNS\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.37      0.73      0.49      1750\n",
      "         neu       0.17      0.04      0.06      1515\n",
      "         pos       0.53      0.34      0.41      1490\n",
      "\n",
      "    accuracy                           0.39      4755\n",
      "   macro avg       0.36      0.37      0.32      4755\n",
      "weighted avg       0.36      0.39      0.33      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_5('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_5('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_5('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output\n",
    "print(\"NOUNS\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_6(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet, lemmatize=True, parts_of_speech_to_consider={'NOUN'}) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEMMA+NOUN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.36      0.71      0.48      1750\n",
      "         neu       0.17      0.04      0.07      1515\n",
      "         pos       0.52      0.33      0.40      1490\n",
      "\n",
      "    accuracy                           0.38      4755\n",
      "   macro avg       0.35      0.36      0.32      4755\n",
      "weighted avg       0.35      0.38      0.33      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_6('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_6('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_6('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output\n",
    "print(\"LEMMA+NOUN\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_7(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet, parts_of_speech_to_consider={'VERB'}) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.32      0.59      0.42      1750\n",
      "         neu       0.16      0.07      0.10      1515\n",
      "         pos       0.57      0.34      0.43      1490\n",
      "\n",
      "    accuracy                           0.35      4755\n",
      "   macro avg       0.35      0.34      0.31      4755\n",
      "weighted avg       0.35      0.35      0.32      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_7('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_7('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_7('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output\n",
    "print(\"VERB\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyse_8(sent, content):\n",
    "    tweets = []\n",
    "    all_vader_output = []\n",
    "    gold = []\n",
    "\n",
    "    # settings (to change for different experiments)\n",
    "    to_lemmatize = True \n",
    "    pos = set()\n",
    "    gold = [sent for i in range(len(content))]\n",
    "\n",
    "    for i in range(len(content)):\n",
    "        the_tweet = content[i]\n",
    "        vader_output = run_vader(the_tweet, lemmatize=True, parts_of_speech_to_consider={'VERB'}) # run vader\n",
    "        vader_label = vader_output_to_label(vader_output) # convert vader output to category\n",
    "        \n",
    "        tweets.append(the_tweet)\n",
    "        all_vader_output.append(vader_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "    for i in range(len(all_vader_output)):\n",
    "        if all_vader_output[i] == 'neutral':\n",
    "            all_vader_output[i] = 'neg'\n",
    "        elif all_vader_output[i] == 'positive':\n",
    "            all_vader_output[i] = 'pos'\n",
    "        else:\n",
    "            all_vader_output[i] = 'neu'\n",
    "\n",
    "    # print(\"GOLD LABELS:\", gold)\n",
    "    # print(\"VADER LABELS:\",all_vader_output)\n",
    "\n",
    "    return gold, all_vader_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEMMA + VERB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.33      0.59      0.42      1750\n",
      "         neu       0.19      0.09      0.12      1515\n",
      "         pos       0.57      0.35      0.43      1490\n",
      "\n",
      "    accuracy                           0.36      4755\n",
      "   macro avg       0.36      0.34      0.33      4755\n",
      "weighted avg       0.36      0.36      0.33      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_gold, pos_all_vader_output = vader_analyse_8('pos', get_content('positive'))\n",
    "neu_gold, neu_all_vader_output = vader_analyse_8('neu', get_content('neutral'))\n",
    "neg_gold, neg_all_vader_output = vader_analyse_8('neg', get_content('negative'))\n",
    "\n",
    "\n",
    "gold = pos_gold + neu_gold + neg_gold\n",
    "\n",
    "all_vader_output = pos_all_vader_output + neu_all_vader_output + neg_all_vader_output\n",
    "print(\"LEMMA + VERB\")\n",
    "# use scikit-learn's classification report\n",
    "print(classification_report(y_true=gold, y_pred=all_vader_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: scikit-learn assignments\n",
    "\n",
    "Train the scikit-learn classifier (Naive Bayes) using the airline tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sklearn\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/mihaly/Documents/uni/VU/text_mining/ba-text-mining/lab_sessions/lab3/airlinetweets\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "airline_tweets_folder = cwd.joinpath('airlinetweets')\n",
    "print('path:', airline_tweets_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_tweets_train = load_files(str(airline_tweets_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important features:\n",
      "Important words in negative documents\n",
      "0 1537.0 @\n",
      "0 1412.0 united\n",
      "0 1259.0 .\n",
      "0 418.0 ``\n",
      "0 399.0 ?\n",
      "0 393.0 flight\n",
      "0 341.0 !\n",
      "0 337.0 #\n",
      "0 220.0 n't\n",
      "0 141.0 ''\n",
      "0 120.0 's\n",
      "0 114.0 service\n",
      "0 111.0 :\n",
      "0 109.0 virginamerica\n",
      "0 102.0 get\n",
      "0 98.0 cancelled\n",
      "0 95.0 delayed\n",
      "0 89.0 plane\n",
      "0 89.0 customer\n",
      "0 85.0 time\n",
      "0 83.0 bag\n",
      "0 81.0 'm\n",
      "0 75.0 -\n",
      "0 74.0 ;\n",
      "0 69.0 gate\n",
      "0 68.0 ...\n",
      "0 67.0 http\n",
      "0 67.0 &\n",
      "0 65.0 hours\n",
      "0 64.0 help\n",
      "0 62.0 still\n",
      "0 62.0 late\n",
      "0 62.0 hour\n",
      "0 62.0 2\n",
      "0 60.0 airline\n",
      "0 59.0 would\n",
      "0 58.0 amp\n",
      "0 55.0 one\n",
      "0 53.0 flights\n",
      "0 53.0 delay\n",
      "0 49.0 like\n",
      "0 49.0 flightled\n",
      "0 49.0 ca\n",
      "0 48.0 waiting\n",
      "0 48.0 never\n",
      "0 46.0 worst\n",
      "0 46.0 $\n",
      "0 45.0 (\n",
      "0 44.0 3\n",
      "0 44.0 )\n",
      "0 43.0 us\n",
      "0 43.0 've\n",
      "0 42.0 back\n",
      "0 41.0 fly\n",
      "0 40.0 seat\n",
      "0 40.0 luggage\n",
      "0 39.0 really\n",
      "0 39.0 due\n",
      "0 38.0 check\n",
      "0 37.0 ticket\n",
      "0 37.0 lost\n",
      "0 35.0 people\n",
      "0 35.0 day\n",
      "0 35.0 bags\n",
      "0 35.0 another\n",
      "0 34.0 ever\n",
      "0 33.0 wait\n",
      "0 33.0 u\n",
      "0 33.0 trying\n",
      "0 33.0 thanks\n",
      "0 33.0 going\n",
      "0 33.0 baggage\n",
      "0 32.0 staff\n",
      "0 31.0 got\n",
      "0 31.0 could\n",
      "0 31.0 airport\n",
      "0 30.0 terrible\n",
      "0 30.0 need\n",
      "0 30.0 last\n",
      "0 30.0 guys\n",
      "-----------------------------------------\n",
      "Important words in neutral documents\n",
      "1 1368.0 @\n",
      "1 496.0 .\n",
      "1 491.0 ?\n",
      "1 300.0 jetblue\n",
      "1 288.0 :\n",
      "1 265.0 united\n",
      "1 252.0 southwestair\n",
      "1 247.0 #\n",
      "1 225.0 ``\n",
      "1 222.0 flight\n",
      "1 190.0 americanair\n",
      "1 174.0 http\n",
      "1 156.0 !\n",
      "1 143.0 usairways\n",
      "1 132.0 's\n",
      "1 80.0 get\n",
      "1 67.0 -\n",
      "1 66.0 flights\n",
      "1 65.0 virginamerica\n",
      "1 62.0 )\n",
      "1 58.0 please\n",
      "1 57.0 help\n",
      "1 57.0 ''\n",
      "1 55.0 (\n",
      "1 53.0 n't\n",
      "1 49.0 need\n",
      "1 47.0 ;\n",
      "1 42.0 us\n",
      "1 41.0 fleet\n",
      "1 41.0 fleek\n",
      "1 41.0 ...\n",
      "1 40.0 ”\n",
      "1 40.0 tomorrow\n",
      "1 40.0 dm\n",
      "1 40.0 &\n",
      "1 39.0 “\n",
      "1 37.0 know\n",
      "1 36.0 would\n",
      "1 33.0 flying\n",
      "1 32.0 'm\n",
      "1 31.0 way\n",
      "1 30.0 amp\n",
      "1 29.0 like\n",
      "1 29.0 hi\n",
      "1 29.0 change\n",
      "1 27.0 thanks\n",
      "1 27.0 fly\n",
      "1 26.0 number\n",
      "1 26.0 new\n",
      "1 25.0 one\n",
      "1 25.0 cancelled\n",
      "1 25.0 airport\n",
      "1 24.0 today\n",
      "1 23.0 rt\n",
      "1 23.0 go\n",
      "1 23.0 could\n",
      "1 22.0 time\n",
      "1 22.0 see\n",
      "1 22.0 destinationdragons\n",
      "1 21.0 use\n",
      "1 21.0 bag\n",
      "1 21.0 back\n",
      "1 20.0 travel\n",
      "1 20.0 ticket\n",
      "1 20.0 sent\n",
      "1 20.0 check\n",
      "1 20.0 chance\n",
      "1 19.0 trip\n",
      "1 19.0 tickets\n",
      "1 19.0 guys\n",
      "1 18.0 weather\n",
      "1 18.0 start\n",
      "1 18.0 seat\n",
      "1 18.0 lax\n",
      "1 18.0 follow\n",
      "1 17.0 want\n",
      "1 17.0 trying\n",
      "1 17.0 next\n",
      "1 17.0 going\n",
      "1 17.0 gate\n",
      "-----------------------------------------\n",
      "Important words in positive documents\n",
      "2 1337.0 @\n",
      "2 1056.0 !\n",
      "2 760.0 .\n",
      "2 316.0 southwestair\n",
      "2 298.0 #\n",
      "2 285.0 thanks\n",
      "2 281.0 jetblue\n",
      "2 258.0 thank\n",
      "2 250.0 united\n",
      "2 230.0 ``\n",
      "2 181.0 :\n",
      "2 178.0 flight\n",
      "2 175.0 americanair\n",
      "2 139.0 great\n",
      "2 129.0 usairways\n",
      "2 96.0 service\n",
      "2 91.0 )\n",
      "2 85.0 virginamerica\n",
      "2 77.0 http\n",
      "2 69.0 love\n",
      "2 69.0 customer\n",
      "2 64.0 guys\n",
      "2 62.0 awesome\n",
      "2 61.0 best\n",
      "2 60.0 's\n",
      "2 59.0 much\n",
      "2 54.0 time\n",
      "2 53.0 -\n",
      "2 50.0 ;\n",
      "2 49.0 good\n",
      "2 49.0 airline\n",
      "2 43.0 got\n",
      "2 41.0 today\n",
      "2 41.0 crew\n",
      "2 40.0 us\n",
      "2 40.0 n't\n",
      "2 40.0 get\n",
      "2 38.0 help\n",
      "2 37.0 amazing\n",
      "2 35.0 &\n",
      "2 34.0 fly\n",
      "2 33.0 flying\n",
      "2 32.0 back\n",
      "2 31.0 made\n",
      "2 31.0 gate\n",
      "2 31.0 ...\n",
      "2 30.0 response\n",
      "2 29.0 appreciate\n",
      "2 29.0 amp\n",
      "2 28.0 home\n",
      "2 28.0 ever\n",
      "2 28.0 day\n",
      "2 28.0 'm\n",
      "2 25.0 're\n",
      "2 24.0 tonight\n",
      "2 24.0 nice\n",
      "2 24.0 flights\n",
      "2 24.0 'll\n",
      "2 23.0 see\n",
      "2 23.0 new\n",
      "2 23.0 know\n",
      "2 23.0 ?\n",
      "2 23.0 ''\n",
      "2 22.0 work\n",
      "2 22.0 u\n",
      "2 22.0 staff\n",
      "2 22.0 first\n",
      "2 21.0 yes\n",
      "2 21.0 always\n",
      "2 21.0 (\n",
      "2 20.0 team\n",
      "2 20.0 job\n",
      "2 20.0 helpful\n",
      "2 20.0 happy\n",
      "2 20.0 class\n",
      "2 20.0 agent\n",
      "2 19.0 would\n",
      "2 19.0 plane\n",
      "2 19.0 finally\n",
      "2 18.0 well\n",
      "\n",
      "Vectorization: Bag of Words\n",
      "Min DF: 2\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       315\n",
      "           1       0.87      0.72      0.79       339\n",
      "           2       0.82      0.85      0.83       297\n",
      "\n",
      "    accuracy                           0.83       951\n",
      "   macro avg       0.83      0.83      0.82       951\n",
      "weighted avg       0.83      0.83      0.82       951\n",
      " \n",
      "\n",
      "Vectorization: TF-IDF\n",
      "Min DF: 2\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       363\n",
      "           1       0.88      0.71      0.79       300\n",
      "           2       0.84      0.87      0.85       288\n",
      "\n",
      "    accuracy                           0.84       951\n",
      "   macro avg       0.85      0.84      0.84       951\n",
      "weighted avg       0.85      0.84      0.84       951\n",
      " \n",
      "\n",
      "Vectorization: Bag of Words\n",
      "Min DF: 5\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       359\n",
      "           1       0.83      0.73      0.78       291\n",
      "           2       0.83      0.85      0.84       301\n",
      "\n",
      "    accuracy                           0.83       951\n",
      "   macro avg       0.83      0.83      0.83       951\n",
      "weighted avg       0.83      0.83      0.83       951\n",
      " \n",
      "\n",
      "Vectorization: TF-IDF\n",
      "Min DF: 5\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       353\n",
      "           1       0.86      0.73      0.79       328\n",
      "           2       0.79      0.85      0.82       270\n",
      "\n",
      "    accuracy                           0.83       951\n",
      "   macro avg       0.83      0.83      0.82       951\n",
      "weighted avg       0.83      0.83      0.82       951\n",
      " \n",
      "\n",
      "Vectorization: Bag of Words\n",
      "Min DF: 10\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       310\n",
      "           1       0.82      0.75      0.78       335\n",
      "           2       0.84      0.84      0.84       306\n",
      "\n",
      "    accuracy                           0.82       951\n",
      "   macro avg       0.83      0.83      0.82       951\n",
      "weighted avg       0.82      0.82      0.82       951\n",
      " \n",
      "\n",
      "Vectorization: TF-IDF\n",
      "Min DF: 10\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       345\n",
      "           1       0.75      0.77      0.76       278\n",
      "           2       0.86      0.79      0.82       328\n",
      "\n",
      "    accuracy                           0.82       951\n",
      "   macro avg       0.82      0.82      0.82       951\n",
      "weighted avg       0.82      0.82      0.82       951\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#warnings are annoying, this way we supress them\n",
    "#thanks to https://stackoverflow.com/a/33616192\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "#for question 6\n",
    "def important_features_per_class(vectorizer,classifier,n=80):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names =vectorizer.get_feature_names_out()\n",
    "    topn_class1 = sorted(zip(classifier.feature_count_[0], feature_names),reverse=True)[:n]\n",
    "    topn_class2 = sorted(zip(classifier.feature_count_[1], feature_names),reverse=True)[:n]\n",
    "    topn_class3 = sorted(zip(classifier.feature_count_[2], feature_names),reverse=True)[:n]\n",
    "    print(\"Important words in negative documents\")\n",
    "    for coef, feat in topn_class1:\n",
    "        print(class_labels[0], coef, feat)\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in neutral documents\")\n",
    "    for coef, feat in topn_class2:\n",
    "        print(class_labels[1], coef, feat) \n",
    "    print(\"-----------------------------------------\")\n",
    "    print(\"Important words in positive documents\")\n",
    "    for coef, feat in topn_class3:\n",
    "        print(class_labels[2], coef, feat) \n",
    "\n",
    "#list of all the df values we want to test: \n",
    "min_dfs = [2,5,10]\n",
    "\n",
    "#we will store the different vectorizings in this list\n",
    "vectorized = []\n",
    "\n",
    "#transformer init\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "for min_df in min_dfs:\n",
    "    airline_vec = CountVectorizer(min_df=min_df, # iterating through the values we want to test\n",
    "                             tokenizer=nltk.word_tokenize,\n",
    "                             stop_words=stopwords.words('english'))\n",
    "    \n",
    "    #we have to redo these due to changing min_df\n",
    "    airline_counts = airline_vec.fit_transform(airline_tweets_train.data)\n",
    "    vectorized.append(airline_counts)\n",
    "    \n",
    "    airline_tfidf = tfidf_transformer.fit_transform(airline_counts)\n",
    "    vectorized.append(airline_tfidf)\n",
    "    \n",
    "    for index, representation in enumerate(vectorized):\n",
    "        \n",
    "        docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "        representation, # the current representation\n",
    "        airline_tweets_train.target, # the category values for each tweet \n",
    "        test_size = 0.20 # we use 80% for training and 20% for development\n",
    "        ) \n",
    "        \n",
    "        clf = MultinomialNB().fit(docs_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(docs_test)\n",
    "        \n",
    "        #for question 6\n",
    "        if min_df == 2 and not index:\n",
    "            print (\"Important features:\")\n",
    "            important_features_per_class(airline_vec, clf)\n",
    "            print()\n",
    "        \n",
    "        print(\"Vectorization:\", \"TF-IDF\" if index else \"Bag of Words\")\n",
    "        print(\"Min DF:\", min_df)\n",
    "        print(\"Classification report:\")\n",
    "        print(classification_report(y_true=y_test,\n",
    "                                    y_pred=y_pred), \"\\n\")\n",
    "        \n",
    "        \n",
    "    #clear after every iteration\n",
    "    vectorized.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
